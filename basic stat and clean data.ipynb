{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5951d1fb-4dbe-422b-acfb-540ae3ed307b",
   "metadata": {},
   "source": [
    "# Basic stat and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb14bf3-9db5-4b95-a63d-ff4c3c693a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_ori=r\"original data path\"\n",
    "\n",
    "dat_work=r\"working folder path\"\n",
    "\n",
    "path_results=r\"result folder path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef87b9d7-48ca-4150-a4f9-c876fd714dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6b4fb3-6770-4b5f-8f25-a1e68b336728",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ROOT = Path(dat_ori)  # p00\n",
    "\n",
    "\n",
    "ECG_LEADS = {\n",
    "    \"I\",\"II\",\"III\",\"AVR\",\"AVL\",\"AVF\",\n",
    "    \"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\n",
    "    \"MCL1\",\"MCL2\",\"MCL3\",\"MCL4\",\"MCL5\",\"MCL6\",\n",
    "    \"V\",\"VX\",\"VE\",\"VF\" \n",
    "}\n",
    "\n",
    "PPG_COLOR_KEYS = {\n",
    "    \"RED\": [\"RED\"],\n",
    "    \"IR\": [\"IR\",\"INFRA\",\"INFRARED\"],\n",
    "    \"GREEN\": [\"GREEN\"],\n",
    "    \"BLUE\": [\"BLUE\"]\n",
    "}\n",
    "\n",
    "def norm_name(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \"\", s.upper())\n",
    "\n",
    "def classify_channel(name: str):\n",
    "    \"\"\"\n",
    "    return data: ECG/PPG/ABG etc\n",
    "    \"\"\"\n",
    "    n = norm_name(name)\n",
    "\n",
    "    # --- ECG ---\n",
    "    if n in ECG_LEADS:\n",
    "        return (\"ECG\", n)\n",
    "    # robust on ECG name LeadII / ECGII / ECG2\n",
    "    m = re.match(r\"(LEAD)?(ECG)?(I{1,3}|V[1-6]|AVR|AVL|AVF)$\", n)\n",
    "    if m:\n",
    "        lead = m.groups()[-1]\n",
    "        return (\"ECG\", lead)\n",
    "\n",
    "    # --- PPG / Pleth ---\n",
    "    if \"PLETH\" in n or \"PPG\" in n or \"PHOTO\" in n:\n",
    "        # PPG color\n",
    "        for color, keys in PPG_COLOR_KEYS.items():\n",
    "            if any(k in n for k in keys):\n",
    "                return (\"PPG\", color)\n",
    "        return (\"PPG\", \"UNKNOWN\")\n",
    "\n",
    "    # BP\n",
    "    if n in {\"ABP\",\"ART\",\"AOP\"}:\n",
    "        return (\"BP\", \"ABP/ART\")\n",
    "    if n in {\"PAP\"}:\n",
    "        return (\"BP\", \"PAP\")\n",
    "    if n in {\"CVP\"}:\n",
    "        return (\"BP\", \"CVP\")\n",
    "    if n in {\"UAP\",\"FAP\",\"RAP\",\"PCWP\",\"ICP\"}:\n",
    "        return (\"BP\", n)\n",
    "\n",
    "    # RESP\n",
    "    if n in {\"RESP\",\"RESPIRATION\"}:\n",
    "        return (\"RESP\", \"RESP\")\n",
    "    if \"ETCO2\" in n or n == \"CO2\":\n",
    "        return (\"CO2\", \"CO2\")\n",
    "    if n in {\"SPO2\",\"O2\"}:\n",
    "        return (\"O2\", n)\n",
    "\n",
    "    # other\n",
    "    if n.startswith(\"EEG\"):\n",
    "        return (\"EEG\", n)\n",
    "    if n.startswith(\"EMG\"):\n",
    "        return (\"EMG\", n)\n",
    "\n",
    "    return (\"OTHER\", name)\n",
    "\n",
    "# check in all head files\n",
    "hea_files = list(ROOT.rglob(\"*.hea\"))\n",
    "\n",
    "records_info = []\n",
    "counter_by_raw = Counter()         \n",
    "counter_by_group = Counter()       \n",
    "counter_ecg_lead = Counter()      \n",
    "counter_ppg_color = Counter()    \n",
    "\n",
    "fail_list = []\n",
    "\n",
    "for hea_path in tqdm(hea_files, desc=\"Scanning .hea\"):\n",
    "    try:\n",
    "        rec_base = str(hea_path)[:-4]  \n",
    "        h = wfdb.rdheader(rec_base)\n",
    "        sig_names = list(h.sig_name) if h.sig_name else []\n",
    "        units = list(h.units) if h.units else []\n",
    "        fs = h.fs\n",
    "        n_sig = h.n_sig\n",
    "\n",
    "        records_info.append({\n",
    "            \"record\": Path(rec_base).name,\n",
    "            \"rel_dir\": str(hea_path.parent.relative_to(ROOT)),\n",
    "            \"fs\": fs,\n",
    "            \"n_sig\": n_sig,\n",
    "            \"channels\": \";\".join(sig_names),\n",
    "            \"units\": \";\".join(units) if units else \"\"\n",
    "        })\n",
    "\n",
    "        for ch in sig_names:\n",
    "            counter_by_raw[norm_name(ch)] += 1\n",
    "            big, small = classify_channel(ch)\n",
    "            counter_by_group[big] += 1\n",
    "            if big == \"ECG\":\n",
    "                counter_ecg_lead[small] += 1\n",
    "            if big == \"PPG\":\n",
    "                counter_ppg_color[small] += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        fail_list.append({\"hea\": str(hea_path), \"error\": repr(e)})\n",
    "\n",
    "# summarise\n",
    "df_records = pd.DataFrame(records_info).sort_values(\"record\")\n",
    "\n",
    "df_raw = (pd.DataFrame(counter_by_raw.items(), columns=[\"raw_channel\",\"count\"])\n",
    "            .sort_values(\"count\", ascending=False))\n",
    "df_group = (pd.DataFrame(counter_by_group.items(), columns=[\"group\",\"count\"])\n",
    "            .sort_values(\"count\", ascending=False))\n",
    "df_ecg = (pd.DataFrame(counter_ecg_lead.items(), columns=[\"ecg_lead\",\"count\"])\n",
    "            .sort_values(\"count\", ascending=False))\n",
    "df_ppg = (pd.DataFrame(counter_ppg_color.items(), columns=[\"ppg_color\",\"count\"])\n",
    "            .sort_values(\"count\", ascending=False))\n",
    "\n",
    "print(\"total record \", len(df_records))\n",
    "print(\"read fail \", len(fail_list))\n",
    "\n",
    "# output\n",
    "out_dir = Path(path_results) / \"_descriptive_summary\"\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "df_records.to_csv(out_dir / \"records_summary.csv\", index=False)         \n",
    "df_raw.to_csv(out_dir / \"channel_raw_counts.csv\", index=False)         \n",
    "df_group.to_csv(out_dir / \"channel_group_counts.csv\", index=False)     \n",
    "df_ecg.to_csv(out_dir / \"ecg_lead_counts.csv\", index=False)           \n",
    "df_ppg.to_csv(out_dir / \"ppg_color_counts.csv\", index=False)          \n",
    "\n",
    "if fail_list:\n",
    "    pd.DataFrame(fail_list).to_csv(out_dir / \"read_failures.csv\", index=False)\n",
    "\n",
    "out_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6990fdba-81b6-4b3d-8f7f-d2264072a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data we will use\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "import numpy as np\n",
    "\n",
    "ROOT = Path(dat_ori)     # p00\n",
    "OUT_DIR = Path(dat_work) / \"_triad_csv\" \n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \"\", s.upper()) if s else \"\"\n",
    "\n",
    "ECG_II_PATTERNS = [\n",
    "    r\"^II$\", r\"^ECGII$\", r\"^LEADII$\", r\"^LEAD2$\", r\"^ECG2$\", r\"^MCL2$\"\n",
    "]\n",
    "ecg_ii_regex = re.compile(\"|\".join(ECG_II_PATTERNS))\n",
    "\n",
    "# PPG\n",
    "def is_ppg(name_norm: str) -> bool:\n",
    "    if any(k in name_norm for k in [\"PLETH\", \"PPG\", \"PHOTO\"]):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# ABP\n",
    "def is_abp(name_norm: str) -> bool:\n",
    "    if name_norm in {\"ABP\", \"ART\", \"AOP\"}:\n",
    "        return True\n",
    "        \n",
    "    if re.match(r\"^(ABP|ART)\\d+$\", name_norm):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def find_channel_indices(sig_names):\n",
    "    \"\"\"return(ECG_II_idx, PPG_idx, ABP_idx)\"\"\"\n",
    "    names_norm = [norm(x) for x in sig_names]\n",
    "\n",
    "    # ECG II\n",
    "    idx_ecg = None\n",
    "    for i, n in enumerate(names_norm):\n",
    "        if ecg_ii_regex.match(n):\n",
    "            idx_ecg = i\n",
    "            break\n",
    "\n",
    "    # PPG\n",
    "    idx_ppg = None\n",
    "    for i, n in enumerate(names_norm):\n",
    "        if is_ppg(n):\n",
    "            idx_ppg = i\n",
    "            break\n",
    "\n",
    "    # ABP\n",
    "    idx_abp = None\n",
    "    for i, n in enumerate(names_norm):\n",
    "        if is_abp(n):\n",
    "            idx_abp = i\n",
    "            break\n",
    "\n",
    "    if idx_ecg is None or idx_ppg is None or idx_abp is None:\n",
    "        return None\n",
    "    return idx_ecg, idx_ppg, idx_abp\n",
    "\n",
    "# select useful data\n",
    "hea_files = list(ROOT.rglob(\"*.hea\"))\n",
    "selected = []   \n",
    "\n",
    "for hea_path in tqdm(hea_files, desc=\"Scanning headers\"):\n",
    "    rec_base = str(hea_path)[:-4]  \n",
    "    try:\n",
    "        h = wfdb.rdheader(rec_base)\n",
    "        sig_names = list(h.sig_name) if h.sig_name else []\n",
    "        idxs = find_channel_indices(sig_names)\n",
    "        if idxs is not None:\n",
    "            selected.append((rec_base, idxs, sig_names))\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "print(f\"满足(ECG II + PPG + ABP)的记录数：{len(selected)}\")\n",
    "\n",
    "# uotput into csv\n",
    "fail = []\n",
    "for rec_base, (i_ecg, i_ppg, i_abp), sig_names in tqdm(selected, desc=\"Exporting CSV\"):\n",
    "    try:\n",
    "        rec = wfdb.rdrecord(rec_base, channels=[i_ecg, i_ppg, i_abp])\n",
    "    \n",
    "        data = rec.p_signal  # (N, 3)\n",
    "        N = data.shape[0]\n",
    "    \n",
    "        # time\n",
    "        t_sec = np.arange(N) / float(rec.fs)\n",
    "    \n",
    "        # DataFrame\n",
    "        cols = [\"ECG_II\", \"PPG\", \"ABP\"]\n",
    "        try:\n",
    "            units = rec.units  \n",
    "        except:\n",
    "            units = [None, None, None]\n",
    "        colnames = [f\"{c} ({u})\" if u else c for c, u in zip(cols, units)]\n",
    "    \n",
    "        df = pd.DataFrame(data, columns=colnames)\n",
    "        df.insert(0, \"t_sec\", t_sec)  \n",
    "    \n",
    "        rec_id = Path(rec_base).name\n",
    "        out_path = OUT_DIR / f\"{rec_id}.csv\"\n",
    "        df.to_csv(out_path, index=False)\n",
    "    except Exception as e:\n",
    "        fail.append({\"record\": Path(rec_base).name, \"error\": repr(e)})\n",
    "\n",
    "print(\"output finish. fail num \", len(fail))\n",
    "if fail:\n",
    "    pd.DataFrame(fail).to_csv(OUT_DIR / \"_export_failures.csv\", index=False)\n",
    "\n",
    "OUT_DIR\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_11785",
   "language": "python",
   "name": "project_11785"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
