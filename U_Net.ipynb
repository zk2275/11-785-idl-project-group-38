{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Modified Code for PPG-to-ECG Synthesis (using U-Net)"
      ],
      "metadata": {
        "id": "rSjsel2kaRL6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmlFI7mcZ9vr",
        "outputId": "1bc6a266-ab64-4e65-ee7f-bbec4c646594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "--- Starting U-Net PPG-to-ECG Model ---\n"
          ]
        }
      ],
      "source": [
        "# === 1. Install and Import Libraries ===\n",
        "\n",
        "# Install xlrd if not already present\n",
        "!pip install -q xlrd\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings\n",
        "import shutil\n",
        "\n",
        "# Scipy for signal processing\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "# Sklearn for metrics\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# TensorFlow/Keras for Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Conv1DTranspose, LayerNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# === 2. Mount Drive & Define Data Functions ===\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def unzip_data(zip_path, extract_folder):\n",
        "    \"\"\"Unzips a file and returns a list of all .csv files inside.\"\"\"\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(f\"Error: {zip_path} not found. Check your Google Drive path.\")\n",
        "        return []\n",
        "    os.makedirs(extract_folder, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_folder)\n",
        "    csv_files = glob.glob(os.path.join(extract_folder, '**/*.csv'), recursive=True)\n",
        "    print(f\"Extracted {len(csv_files)} files from {zip_path}\")\n",
        "    return csv_files\n",
        "\n",
        "def create_sequences_ppg_to_ecg(df, seq_length=256, step=128):\n",
        "    \"\"\"\n",
        "    Creates overlapping sequences for PPG-to-ECG translation.\n",
        "    Input (X) is PPG signal.\n",
        "    Output (y) is ECG signal.\n",
        "    \"\"\"\n",
        "    ecg = df['ECG'].values\n",
        "    ppg = df['PPG'].values\n",
        "\n",
        "    # Normalize signals individually\n",
        "    ecg = (ecg - np.mean(ecg)) / (np.std(ecg) + 1e-6)\n",
        "    ppg = (ppg - np.mean(ppg)) / (np.std(ppg) + 1e-6)\n",
        "\n",
        "    X_seq = []\n",
        "    y_seq = []\n",
        "\n",
        "    for i in range(0, len(df) - seq_length, step):\n",
        "        end_idx = i + seq_length\n",
        "\n",
        "        # Input is PPG\n",
        "        X_window = ppg[i:end_idx]\n",
        "\n",
        "        # Output (label) is ECG\n",
        "        y_window = ecg[i:end_idx]\n",
        "\n",
        "        # We can add a simple check to skip flat/dead signals\n",
        "        if np.std(X_window) > 0.1 and np.std(y_window) > 0.1:\n",
        "            X_seq.append(X_window)\n",
        "            y_seq.append(y_window)\n",
        "\n",
        "    # Add a \"channels\" dimension for Conv1D\n",
        "    return np.expand_dims(np.array(X_seq), -1), np.expand_dims(np.array(y_seq), -1)\n",
        "\n",
        "def load_and_process(zip_path, extract_folder, seq_length=256, debug_limit=None):\n",
        "    \"\"\"Main function to load zips and process all files for sequence models.\"\"\"\n",
        "    file_list = unzip_data(zip_path, extract_folder)\n",
        "    if debug_limit is not None:\n",
        "        file_list = file_list[:debug_limit]\n",
        "        print(f\"--- DEBUG MODE: Processing only {len(file_list)} files. ---\")\n",
        "\n",
        "    if not file_list: return np.array([]), np.array([])\n",
        "    all_X, all_y = [], []\n",
        "\n",
        "    for f in tqdm(file_list, desc=f\"Processing {zip_path}\"):\n",
        "        try:\n",
        "            df = pd.read_csv(f)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not read {f}: {e}\")\n",
        "            continue\n",
        "        if not all(col in df.columns for col in ['t_sec', 'ECG', 'PPG', 'ABP']):\n",
        "            print(f\"Skipping {f}: missing required columns.\")\n",
        "            continue\n",
        "\n",
        "        # Use the new sequence creation function\n",
        "        X, y = create_sequences_ppg_to_ecg(df, seq_length=seq_length)\n",
        "        if X.shape[0] > 0:\n",
        "            all_X.append(X)\n",
        "            all_y.append(y)\n",
        "\n",
        "    if not all_X:\n",
        "        print(f\"No valid data found in {zip_path} for sequence mode.\")\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    all_X = np.concatenate(all_X, axis=0)\n",
        "    all_y = np.concatenate(all_y, axis=0)\n",
        "    print(f\"Finished processing {zip_path}. Found {all_X.shape[0]} samples.\")\n",
        "    return all_X, all_y\n",
        "\n",
        "# === 3. U-Net Model Definition ===\n",
        "\n",
        "def conv_block(inputs, num_filters):\n",
        "    \"\"\"A block of two 1D convolutions with ReLU activation.\"\"\"\n",
        "    x = Conv1D(num_filters, 3, activation='relu', padding='same')(inputs)\n",
        "    x = Conv1D(num_filters, 3, activation='relu', padding='same')(x)\n",
        "    return x\n",
        "\n",
        "def build_unet_1d(input_shape=(256, 1)):\n",
        "    \"\"\"Builds a 1D U-Net model for signal-to-signal translation.\"\"\"\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Encoder (Downsampling path)\n",
        "    c1 = conv_block(inputs, 16)\n",
        "    p1 = MaxPooling1D(2)(c1)\n",
        "\n",
        "    c2 = conv_block(p1, 32)\n",
        "    p2 = MaxPooling1D(2)(c2)\n",
        "\n",
        "    c3 = conv_block(p2, 64)\n",
        "    p3 = MaxPooling1D(2)(c3)\n",
        "\n",
        "    c4 = conv_block(p3, 128)\n",
        "    p4 = MaxPooling1D(2)(c4)\n",
        "\n",
        "    # Bottleneck\n",
        "    b = conv_block(p4, 256)\n",
        "\n",
        "    # Decoder (Upsampling path)\n",
        "    u4 = Conv1DTranspose(128, 2, strides=2, padding='same')(b)\n",
        "    u4 = Concatenate()([u4, c4]) # Skip connection\n",
        "    c5 = conv_block(u4, 128)\n",
        "\n",
        "    u3 = Conv1DTranspose(64, 2, strides=2, padding='same')(c5)\n",
        "    u3 = Concatenate()([u3, c3]) # Skip connection\n",
        "    c6 = conv_block(u3, 64)\n",
        "\n",
        "    u2 = Conv1DTranspose(32, 2, strides=2, padding='same')(c6)\n",
        "    u2 = Concatenate()([u2, c2]) # Skip connection\n",
        "    c7 = conv_block(u2, 32)\n",
        "\n",
        "    u1 = Conv1DTranspose(16, 2, strides=2, padding='same')(c7)\n",
        "    u1 = Concatenate()([u1, c1]) # Skip connection\n",
        "    c8 = conv_block(u1, 16)\n",
        "\n",
        "    # Output layer\n",
        "    # Use a 1x1 convolution to map to the desired number of output channels (1 for ECG)\n",
        "    outputs = Conv1D(1, 1, activation='linear')(c8) # 'linear' for regression\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "\n",
        "# === 4. U-Net Model Training and Evaluation ===\n",
        "\n",
        "print(\"\\n--- Starting U-Net PPG-to-ECG Model ---\")\n",
        "\n",
        "# 1. Define Model Parameters\n",
        "# U-Nets work best with input sizes that are powers of 2\n",
        "SEQ_LENGTH = 256\n",
        "STEP = 128\n",
        "NUM_FEATURES = 1  # Input is just PPG\n",
        "NUM_OUTPUTS = 1   # Output is just ECG\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20\n",
        "\n",
        "# --- Define Paths ---\n",
        "# !!! EDIT THESE PATHS !!!\n",
        "train_zip_path = '/content/drive/MyDrive/11785FinalData/train.zip'\n",
        "val_zip_path = '/content/drive/MyDrive/11785FinalData/val.zip'\n",
        "test_zip_path = '/content/drive/MyDrive/11785FinalData/test.zip'\n",
        "\n",
        "# 2. Load and process data\n",
        "X_train_seq, y_train_seq = load_and_process(train_zip_path, 'data/train', seq_length=SEQ_LENGTH)\n",
        "X_val_seq, y_val_seq = load_and_process(val_zip_path, 'data/val', seq_length=SEQ_LENGTH)\n",
        "X_test_seq, y_test_seq = load_and_process(test_zip_path, 'data/test', seq_length=SEQ_LENGTH)\n",
        "\n",
        "if X_train_seq.shape[0] == 0:\n",
        "    print(\"No training data found for sequence-based model. Aborting.\")\n",
        "else:\n",
        "    print(f\"Training data shape: {X_train_seq.shape}\")\n",
        "    print(f\"Training labels shape: {y_train_seq.shape}\")\n",
        "\n",
        "    # 3. Build and compile the U-Net model\n",
        "    input_shape = (SEQ_LENGTH, NUM_FEATURES)\n",
        "\n",
        "    model = build_unet_1d(input_shape)\n",
        "\n",
        "    model.compile(optimizer='adam', tran=['mean_squared_error', 'mean_absolute_error'])\n",
        "    model.summary()\n",
        "\n",
        "    # 4. Train Model\n",
        "    print(\"\\nTraining U-Net model...\")\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_seq, y_train_seq,\n",
        "        validation_data=(X_val_seq, y_val_seq),\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # 5. Evaluate on Test Set\n",
        "    print(\"\\nEvaluating U-Net on test set...\")\n",
        "    # This will return [test_loss, test_mae]\n",
        "    results = model.evaluate(X_test_seq, y_test_seq, batch_size=BATCH_SIZE)\n",
        "    test_loss = results[0]\n",
        "    test_mae = results[1]\n",
        "\n",
        "    # 6. Report Results\n",
        "    print(\"\\n--- U-Net Model Test Results ---\")\n",
        "    print(f\"Test Set MSE (Loss): {test_loss:.4f}\")\n",
        "    print(f\"Test Set MAE:        {test_mae:.4f}\")\n",
        "    print(\"----------------------------------\")\n",
        "\n",
        "    # Optional: Predict a few samples to visualize later\n",
        "    # y_pred_seq = model.predict(X_test_seq[:5])\n",
        "\n",
        "\n",
        "# === 5. Save a Trained Model to Your Drive ===\n",
        "\n",
        "# First, create a path to a folder in your Google Drive\n",
        "save_folder = '/content/drive/My Drive/MyProject'\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "\n",
        "# Define the full path to save your model file\n",
        "model_save_path = os.path.join(save_folder, 'unet_ppg_to_ecg_model.keras')\n",
        "\n",
        "# Save the model\n",
        "try:\n",
        "    model.save(model_save_path)\n",
        "    print(f\"Model successfully saved to: {model_save_path}\")\n",
        "except NameError:\n",
        "    print(\"Could not save model. Make sure you have trained the model and it is in a variable named 'model'.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving: {e}\")"
      ]
    }
  ]
}